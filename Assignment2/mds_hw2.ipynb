{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS hw3\n",
    "#### 資管四 莊翔安 b08303028"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 試簡述何謂維度的詛咒？試列舉一案例說明。\n",
    "> 維度的詛咒在說明當維度增加時，因體積指數增加而使任何演算法需要的資料量將同時指數型上升才能避免因資料稀缺而導致無法獲得良好的結果與統計學上正確且可靠的結果。  \n",
    "> 在自然語言處理(NLP)的領域中，詞嵌入是將單字轉換成高維度向量的過程，倘若資料本身詞彙量不足以支撐過這樣的維度，就會發生維度的詛咒，神經網路模型很有可能因此無法有效訓練，從而導致結果不佳。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) 避免維度詛咒的方法有哪些？\n",
    "> + 以特徵挑選演算法來選取最佳數量和特徵組合\n",
    "> + 以特徵提取的方法找到與原始特徵的最佳線性或非線性組合以降維，如 PCA。\n",
    "> + 更換演算法如 Transfer Learning 可以解決資料稀缺性的問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 試找一個開放數據(e.g. Kaggle 開放數據或第一次作業紅酒數據集)並選一種方法(e.g.線性迴歸或決策樹)，用模擬方法固定樣本數但逐步增加變數個數，試著重新繪製圖3.12，呈現維度與預測(或分類)績效間的關係。(提示：模擬方法可思考如下：(1)先做線性迴歸；(2)重要變數依 p-value 排序；(3)將重要的變數一個個依序放入迴歸並計算 adjusted-R2 作為預測準確度)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsiangan/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "/Users/hsiangan/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhDUlEQVR4nO3deZhU9Z3v8fe3qxd6YadB6GYTUERZRdxi3CZejSaIxqiZLCbxOmY0MZnM3PFmJiaTezOTTCYmN3NNjHdkYowOOokoSUgIJjoGRQXZQcBmaXqBplmb7qaXqvreP7rAttPQDdTpU8vn9Tw8VWepqu/hPJwPv98553fM3RERkeyVE3YBIiISLgWBiEiWUxCIiGQ5BYGISJZTEIiIZLncsAs4VcOGDfNx48aFXYaISFp566239rl7aXfL0i4Ixo0bx8qVK8MuQ0QkrZhZ5YmWqWtIRCTLKQhERLKcgkBEJMspCEREspyCQEQkyykIRESynIJARCTLKQhERNLA91/cyuvb9wfy3QoCEZEUV32wme+/+A4rdhwI5PsVBCIiKe6FNbUA3DyzLJDvVxCIiKQwd+e5VdXMGTeE0UOKAvkNBYGISApbX3OYbfVNgbUGQEEgIpLSnltVQ34khxunjgzsNxQEIiIpqj0W55dra7n2vOEMLMoL7HcUBCIiKeqP79Szv6mNeQF2C4GCQEQkZT23qobBRXlcde7wQH9HQSAikoKOtLSzdFMdN00bRX5usIdqBYGISAr6zYY9tEbjzJsVbLcQKAhERFLSwlU1jB9WzMzRgwL/LQWBiEiKqT10lNd37OfmGWWYWeC/pyAQEUkxz6+pwZ3ArxY6RkEgIpJC3J2Fq2qYPXYwY4YGM6REVwoCEZEUsrG2gXf2NgY6pERXCgIRkRRybEiJm6YFN6REVwoCEZEUEY3FWbS2lqsnlzKoKL/PfldBICKSIv5YsY99ja3Mm1nep7+rIBARSRELV9UwsDCPqyeX9unvKghERFJAY2uU323aw03TRlKQG+nT31YQiIikgN9u2ENLe5xb+mBIia4UBCIiKWDh6mrGDi1i1pjBff7bCgIRkZDtPnyU17b13ZASXSkIRERC9sKa2j4dUqIrBYGISIiODSkxa8wgxg0rDqUGBYGISIg27W5gS90R5s3q23sHOlMQiIiEaOGqGvIixk1T+25Iia4CDQIzu97MtphZhZk9eJL1LjKzmJl9JMh6RERSSTQW54W1tVx17nAGF/fdkBJdBRYEZhYBHgFuAKYAd5rZlBOs921gSVC1iIikole37af+SCu3hHSS+JggWwRzgAp33+7ubcACYG43630e+AWwN8BaRERSzsJV1Qzol8s15w0PtY4gg6AMqOo0XZ2Yd5yZlQHzgEdP9kVmdo+ZrTSzlfX19UkvVESkrzW1RlmysY4bp43q8yElugoyCLq7K8K7TH8f+Ft3j53si9z9MXef7e6zS0v7djAmEZEgLNm4h6PtsVCGlOgqN8DvrgZGd5ouB2q7rDMbWJC4k24Y8EEzi7r78wHWJSISuoWraygfXMjssX0/pERXQQbBCmCSmY0HaoA7gI91XsHdxx97b2Y/AX6lEBCRTLe3oYVXK/Zx39UTQxlSoqvAgsDdo2Z2Px1XA0WA+e6+0czuTSw/6XkBEZFMtWhtLXGHuTPC7xaCYFsEuPtiYHGXed0GgLvfFWQtIiKpYuHqGqaVD2Ti8JKwSwF0Z7GISJ/aWneEjbUN3JwirQFQEIiI9KnnV9cQyTE+NH1U2KUcpyAQEekj8bjzwpparpg0jNL+BWGXc5yCQESkj6zYeYCaQ0dDe+7AiSgIRET6yPNraijKj/CBKSPCLuU9FAQiIn2gpT3Gr9bt5vrzz6IoP9ALNk+ZgkBEpA+8tHkvR1qi3Jxi3UKgIBAR6RMLV9dQ2r+AyycOC7uUP6EgEBEJ2KHmNl7aspe500cRyQl/SImuFAQiIgH79frdtMc8JbuFQEEgIhK4hatqmDS8hPNHDQi7lG4pCEREArRrfzMrKw9y88yylBhptDsKAhGRAL2wpgYgZbuFQEEgIhIYd2fhmhouHj+EskGFYZdzQgoCEZGArK85zPb6ppQbUqIrBYGISECeW1VDfiSHG6aODLuUk1IQiIgEoD0W55dra7n2vOEMLMwLu5yTUhCIiARgWcU+9je1pXy3ECgIREQC8fzqGgYV5XHVucPDLqVHCgIRkSRrbI2yZOMebpw6kvzc1D/Mpn6FIiJpZsmGPbS0x9OiWwgUBCIiSff8mhpGDynkwrGDwy6lVxQEIiJJVNfQwqsV+5g3I3WHlOhKQSAikkS/XFtL3GFumnQLgYJARCSpFq6uYXr5QCaUloRdSq8pCEREkmRr3RE21jak9ABz3VEQiIgkyROv7SSSY9w0bVTYpZwSBYGISBKsrz7M02/u4uMXj6G0f0HY5ZwSBYGIyBmKx52vvrCBocUF/NV154ZdzilTEIiInKFnVlaxpuoQX/ng5JQfYK47CgIRkTNwoKmNb/92M3PGDUmbO4m7UhCIiJyB7yzZzJGWKN+4+fy0uYGsKwWBiMhpWr3rIAtWVPHpy8Yx+awBYZdz2gINAjO73sy2mFmFmT3YzfK5ZrbOzNaY2Uoze1+Q9YiIJEsscYJ4eP8CvviBc8Iu54zkBvXFZhYBHgE+AFQDK8xskbtv6rTa74FF7u5mNg14FpgcVE0iIsny1BuVbKhp4F/vnElJQWCH0j4RZItgDlDh7tvdvQ1YAMztvIK7N7q7JyaLAUdEJMXta2zlO0u2cNmEodw0LbWfR9wbQQZBGVDVabo6Me89zGyemW0Gfg18prsvMrN7El1HK+vr6wMpVkSkt/5p8WZa2mN8Y+4FaXuCuLMgg6C7v50/+R+/uy9098nAzcD/6u6L3P0xd5/t7rNLS0uTW6WIyClYsfMAv1hVzd1XnM3E4ekzsNzJBBkE1cDoTtPlQO2JVnb3V4AJZjYswJpERE5bNBbnq89voGxQIZ+/ZmLY5SRNkEGwAphkZuPNLB+4A1jUeQUzm2iJdpWZzQLygf0B1iQictqeWF7J5j1H+OpNUyjKT+8TxJ0FtiXuHjWz+4ElQASY7+4bzezexPJHgVuBT5pZO3AUuL3TyWMRkZRR19DC95Zu5cpzSvlv548Iu5ykCjTS3H0xsLjLvEc7vf828O0gaxARSYZv/vpt2mJx/uHD6XsH8YnozmIRkR68VrGPRWtruffKCYwbVhx2OUmnIBAROYm2aJyHFm1k9JBC/vKqCWGXE4jMOdshIpJkbdE4Dy/dSsXeRubfNZt+eZGwSwqEgkBEpIuDTW089UYlP11eyd4jrdw0bSTXTM6sE8SdKQhERBK21Tcyf9kOfrGqmpb2OFdMGsZ3bpvO+ydl9u1NCgIRyWruzvJt+/m3ZTv4w+a95OfmMG9GGZ9533jOPat/2OX1CQWBiGSl1miMX67dzePLdvD27gaGFufzwLWT+PglY9Pu4fNnSkEgImmtsTXKip0H2FhzmFi8d59paouycHUN9UdamTS8hG/fOpW5M8oy9mRwT3oMAjMbAJS6+7Yu86e5+7rAKhMR6cbRthgrKw+wfNt+lm/fz7rqw8Tipz4gwfvPKeW7t43niknDMu4GsVN10iAws48C3wf2mlkecJe7r0gs/gkwK9DqRCTrtbTHWLXrIK8nDvxrqg7RHnNyc4xp5QO598qzufTsYcwaO4h+ub3/H31OTnYf/DvrqUXwFeBCd99tZnOAJ83sK+7+HN0PMy0icsYaWtpZuKqG32zYzapdh2iLxskxmFo2kM+8bzyXnj2Ui8YNoTjNnwyWKnr6W4y4+24Ad3/TzK4GfmVm5ehpYiKSZG/vbuDJ1yt5fnUNzW0xJp/Vn09eMpZLJwzlovFDGNAvL+wSM1JPQXDEzCYcOz+QaBlcBTwPnB9saSKSDVqjMX67YQ9PLq9kZeVBCnJz+PD0UXzi0rFMKx8UdnlZoacg+BxdxiNy9yNmdj3w0cCqEpGMV3PoKE+/UckzK6rY19jGuKFF/P2N5/GRC8sZVJQfdnlZ5aRB4O5rT7ColxdpiYi8Kx53llXs46fLK/nD5joArpk8gk9cOpYrJg7TCdyQ9HTV0ADgPjoeOr8IWArcD/w1sAZ4KuD6RCRNxePOrgPNbNrdwMbaw2yqbWBDbQP1R1oZWpzPvVdO4GMXj6F8cFHYpWa9nrqGngQOAsuBu4G/oeNxknPdfU2wpYlIumhpj/FOXSObdh9mY20Dm2obeHt3A01tMQAiOcak4SVcMXEY7z+nlBumnkXBKVzqKcHqKQjOdvepAGb2b8A+YIy7Hwm8MhFJeRV7j/DlZ9eyobbh+E1dxfkRpowawEcuLGfKqAFMGTmQSSNKsvau3XTQUxC0H3vj7jEz26EQEBGAddWH+NT8N4nk5PC5KyckDvoDGDOkSH39aaanIJhuZg2J9wYUJqYNcHcfEGh1IpKSlm/bz91PrGBwcT4/++zFGfn4xmzS01VDasuJyHu8uKmOv3x6FWOHFPHkZy/mrIH9wi5JztApP7PYzO4JohARSX0LV1fzFz97i/PO6s+zf3GpQiBDnM7D6+9NehUikvKeeG0nX3pmLRePH8JT//0SBhfrpq9McTojNukskEgWcXf+9Q8VPLx0K9dNGcEP7pypK4AyzOkEwYeSXoWIpKR43Pnfv36b+a/u4JZZZfzzrdPIjZxOR4Kksp7uLP64u//MzP6qy3zoGH30ALDI3Q8GV6KIhCEai/Pgc+v5+VvV3HXZOB66aYouC81QPbUIjl0TdqInOI+nY2C6S5JWkYiErqU9xgMLVrNkYx1f+rNz+MK1E7P+KV6ZrKfLR3+ceP2HE61jZt9IdlEiEp6m1ij3PLmSVyv287UPTeHTl48PuyQJWE9dQz842XJ3/4K7P5TckkQkTN9bupXl2/bz3dumc+uF5WGXI32gp7M+byX+9KPj+cTvJP7MAGKBViYifW7vkRZ+9kYl82aWKwSySE9dQ08AmNldwNXu3p6YfhT4XeDViUifevTl7bTHnM9fMzHsUqQP9fY6sFG894RxSWKeiGSIvQ0tPPVGJfNmlmnsoCzT2/sIvgWsNrOXEtNXAl8PpCIRCcWP/msb0bhaA9moVy0Cd/934FLgbeA54H8CO3r6nJldb2ZbzKzCzB7sZvmfm9m6xJ/XzGz6KdYvIkmwt6GFp9/YxS0zyxg7VK2BbNOrFoGZ3Q08AJTT8YjKS+h4atk1J/lMBHgE+ABQDawws0XuvqnTajuAK939oJndADwGXHwa2yEiZ+CHL3e0Bu5XayAr9fYcwQPARUClu18NzATqe/jMHKDC3be7exuwAJjbeQV3f63TXcmv0xE0ItKH6hpaePrNXdw6S62BbNXbIGhx9xYAMytw983AuT18pgyo6jRdnZh3Ip8FftPdAjO7x8xWmtnK+vqe8kdETsWPXt5GPO7cf/WksEuRkPT2ZHG1mQ0CngeWmtlBoLaHz3R3P7p3u6LZ1XQEwfu6W+7uj9HRbcTs2bO7/Q4ROXV7Dh9rDZQzZmhR2OVISHoVBO4+L/H264krhwYCv+3hY9XA6E7T5XQTHmY2Dfg34AZ339+bekQkOX70ckVHa0DnBrLaKQ9D7e7/1ctVVwCTzGw8UAPcAXys8wpmNoaOq5A+4e5bT7UWETl9ew638B9vVvGRC8sZPUStgWx2Os8j6BV3j5rZ/cASIALMd/eNZnZvYvmjwEPAUOCHiZENo+4+O6iaRORdP3y5grg7912t1kC2CywIANx9MbC4y7xHO72/G7g7yBpE5E/VHjrKgjeruG22WgNyes8sFpE096OXt6k1IMcpCESyTO2hozyzoorbZo+mfLBaA6IgEMk6P3y5Ase57+oJYZciKUJBIJJFatQakG4oCESyyA9fqgDQuQF5DwWBSJaoPtjMsyur+Ojs0ZQNKgy7HEkhCgKRLPHDl7cBag3In1IQiGSB6oPN/OfKKm6/aDSj1BqQLgK9oUxEwhGPO9v3NbK26jDrqg/xx4p9GMZfXqXWgPwpBYFImnN3qg8eZV11x0F/bfUhNtQ00NgaBaAoP8IFZQP5wjWT1BqQbikIJOO0RmPMX7aTZ1dWkWPQLy9CYV6EwvwIBbkdr4V5Ocfn90v8KS6IUJyfS3FBLiUFuR3TBYnp/I7p3Ei4vanNbVG21zexrb6Rir2NrK85zLrqwxxoagMgP5LDeSP7M29mGdPKBzJ99CAmlJYQyeluVHiRDgoCyRjuzu821fHNX7/NrgPNXDZhKIOL82lpi3G0PUZTa5R9jW20tMdoae+Yd7QtRms03uvfKMjNSYRELkX5kePvSxLT74ZIbrfBUlKQS1EPweLu7G9qo2Jv4/ED/rb6JrbtbaTm0NHj6+UYTBren2snD2fa6EFMLx/IuWf1pyA3kpS/T8keCgLJCFv2HOEbv9rIqxX7mTS8hCc/O4crJpX26rPxuNMSjdHUGqO5LUpja5Sm1o7gaGyNJuZ1TL87L5ZYL8qh5jZqDh09vqypNUq8l49P6hwsxQW55EWMyv3NHD7afnydwrwIE4YXM3vcYO4oHc2E4SVMHF7C2KFFOuhLUigIJK0dam7je0u38rM3dlFSkMs/fPh8/vziMafUhZOTYxTl51KUnwsUnHFN7k5rNH48FLoGy3vmtUU7BUyM1miMG6eNZEJpx8F+QmkxowYWkqOuHQmQgkDSUjQW5+k3d/Hw0q00HG3n45eM5Ut/dg6Di/PDLg0zO37eYVjJmQeLSNAUBJJ0h4+2E43FyY3kkBcxcnM6XhMPHzpjy97Zxzd+tZGtdY1cNmEoD31oCpPPGpCU7xbJRgoCSYp43PljxT6eXL6T32/ei3fTRx7JMXJzjLxIDrmdAqJfXqTjRGt+LoX5HVfvdHTVdLwW50cS83P5w+a9LN1Ux+ghhfz4Exdy3ZQRSQsYkWylIJAz0tDSzs9XVvPk65Xs2NfEsJJ8PnflBEYM6Ed7LE407kRjcdpjTjQeJxrz4+/bYx3LWqJxmlujNLUdO/HacTVPU1uU5tYYbbF3r+opyo/wP64/l89cPp5+eTpRKpIMCgI5LVv2HOGny3eycHUNzW0xZo0ZxBfvmMH1F5yV9CtZ2mNxmts6rugpKcilf7+8pH6/SLZTEGSQmkNH2d/YSn5uDvmRnI7X3BwKIhEK8jrmncnVJ9FYnKWb6nhi+U5e336A/Nwc5k4fxScvHcfU8oFJ3JL3yovkMLAwh4GFCgCRICgIMsSh5jaue/i/aGqLnXS93Bw7HhCFib75ztexv+eO2uM3Q0Woa2jlP97cxe7DLZQNKuTBGybz0dmjGZICV+mIyJlREGSIp9/cRVNbjG/fOpWSgjzaYjHaonHaonFao3HaYvHj022J6WP98MduljrQ1Jy4rr3jZqm2LnfcXjFpGN+YewHXTB6uIQtEMoiCIAO0x+L89LVKLp84lNsvGpPU7z1281NeJIcRA/ol7btFJHUoCDLA4vW72dPQwj/eckFSvzcvksOgonwGFan7RyST6cE0ac7deXzZDs4eVsxV5wwPuxwRSUMKgjT3VuVB1lUf5tOXj9N4NCJyWhQEae7xZTsYWJjHrReWh12KiKQpBUEaqzrQzJKNe7hzzpjEyJkiIqdOQZDGnnhtJ2bGpy4bG3YpIpLGFARpqrE1yjMrqvjg1JGMHKjn0IrI6VMQpKlnV1RxpDXKZ983PuxSRCTNKQjSUCzu/PtrO7hw7GBmjB4UdjkikuYUBGnoxbfrqDpwVK0BEUmKQIPAzK43sy1mVmFmD3azfLKZLTezVjP76yBrySSPL9tB2aBCrpsyIuxSRCQDBBYEZhYBHgFuAKYAd5rZlC6rHQC+APxLUHVkmg01h3lzxwHuumzcKT2gXUTkRII8kswBKtx9u7u3AQuAuZ1XcPe97r4CaA+wjozy+LIdFOdHuH3O6LBLEZEMEWQQlAFVnaarE/NOmZndY2YrzWxlfX19UopLR3UNLfxqXS23zR7NAD2lS0SSJMgg6G7gm24ead4zd3/M3We7++zS0tIzLCt9Pbm8kmjc+fTl48IuRUQySJBBUA107r8oB2oD/L2M1tIe46k3KvnAeSMYO7Q47HJEJIMEGQQrgElmNt7M8oE7gEUB/l5Ge25VDQeb2/mMLhkVkSQLbKQyd4+a2f3AEiACzHf3jWZ2b2L5o2Z2FrASGADEzeyLwBR3bwiqrnTk7sx/dQfnjxrAxeOHhF2OiGSYQIesdPfFwOIu8x7t9H4PHV1GchKvvLOPir2NPPzR6ZjpmQMikly6ED0NPL5sB8P7F3DTtFFhlyIiGUhBkOLeqTvCK1vr+eSlY8nP1e4SkeTTkSXFzX91BwW5OXzsYj1zQESCocdapZBY3NnT0MKu/c1UHWym+kAzz62q4ZZZZQwpzg+7PBHJUAqCM+TufO/Fd3itYh/9++VS0i+PkoLcjvcFiT/9cumfeC0pyMWB6oNHqTrQTPXBZqoOHKXqYDO1h47SHnv3nrscgwmlJdx75YTwNlBEMp6C4AwtWFHFD37/DuePGkBbLE7l/mYaWqI0trbT0h7v8fNDi/MpH1LEtPJB3Dh1JKOHFDF6cBGjhxQyalAheRpYTkQCpiA4AxtqDvO1RRu5YtIwfvLpOURy3ntpZ3ssTlNrlCMtURqPv7bjDuWDiygfXEhxgXaBiIRLR6HT1NDSzn1Pr2JIUT7fv33Gn4QAQF4kh0FF+QwqUv++iKQuBcFpcHf+5j/XUn3wKM/ccwlDSwrCLklE5LSpA/o0PL5sB0s21vHg9ZOZPU5DPohIelMQnKK3Kg/wrd9s5ropI7j7Cg0AJyLpT0FwCg40tXH/06sZNaiQ79ymcX9EJDPoHEEvxePOF59Zw/6mNp773GUMLNQTwkQkM6hF0Ev/96UKXtlaz9c+NIULygaGXY6ISNIoCHrh1Yp9fO/Frdw8YxQfmzMm7HJERJJKQdCDuoYWHliwmgmlJXxz3lSdFxCRjKNzBCfRHotz/9OraG6LseCeWboLWEQyko5sJ/EvS7awYudB/s8dM5g4vH/Y5YiIBEJdQyewdFMdP35lO39+8RjmzigLuxwRkcAoCLpRe+goX352DReUDeCrN00JuxwRkUApCLqIx50vP7uWaNx55GOz6JcXCbskEZFAKQi6mP/qDpZv389DN01h7NDisMsREQmcgqCTLXuO8M9LtvBn543g9otGh12OiEifUBAktEZjPLBgNQP65fKtW3W/gIhkD10+mvDw0q1s3nOExz81m2F6voCIZBG1CIDXt+/nsVe2c+ecMVx73oiwyxER6VNZHwQNLe18+dm1jB1SxN/feF7Y5YiI9Lms7xr6+qKN7D58lJ9/7jINISEiWSmrWwSL1+/muVU13H/1RGaNGRx2OSIiocjaIKhraOErC9czvXwgn792UtjliIiEJiuDwN35m5+vo6U9xsO3zyAvkpV/DSIiQJYGwZOvV/LK1nr+7oPnMaG0JOxyRERCFWgQmNn1ZrbFzCrM7MFulpuZ/SCxfJ2ZzQqyHoCKvY1889dvc+U5pXz8krFB/5yISMoLLAjMLAI8AtwATAHuNLOuQ3neAExK/LkH+FFQ9UDHg2a+9MwaivIjfOcj03T3sIgIwbYI5gAV7r7d3duABcDcLuvMBX7qHV4HBpnZyKAK+sHv32F9zWH+6ZapDB/QL6ifERFJK0EGQRlQ1Wm6OjHvVNdJircqD/LISxXcOquc6y8ILGtERNJOkEHQXb+Ln8Y6mNk9ZrbSzFbW19efVjH5kRwunziMr39YD5oREeksyCCoBjqP5VwO1J7GOrj7Y+4+291nl5aWnlYxU8sH8uRnL6Z/v7zT+ryISKYKMghWAJPMbLyZ5QN3AIu6rLMI+GTi6qFLgMPuvjvAmkREpIvABtdx96iZ3Q8sASLAfHffaGb3JpY/CiwGPghUAM3Ap4OqR0REuhfoKGvuvpiOg33neY92eu/AfUHWICIiJ5eVdxaLiMi7FAQiIllOQSAikuUUBCIiWU5BICKS5azjwp30YWb1QGWnWcOAfSGV01cyfRu1fekv07cxE7ZvrLt3e0du2gVBV2a20t1nh11HkDJ9G7V96S/TtzHTt09dQyIiWU5BICKS5TIhCB4Lu4A+kOnbqO1Lf5m+jRm9fWl/jkBERM5MJrQIRETkDCgIRESyXFoHgZldb2ZbzKzCzB4Mu55kM7OdZrbezNaY2cqw60kGM5tvZnvNbEOneUPMbKmZvZN4HRxmjWfiBNv3dTOrSezHNWb2wTBrPBNmNtrMXjKzt81so5k9kJifEfvwJNuXMfuwO2l7jsDMIsBW4AN0POlsBXCnu28KtbAkMrOdwGx3T/cbWY4zs/cDjcBP3f2CxLx/Bg64+7cSgT7Y3f82zDpP1wm27+tAo7v/S5i1JYOZjQRGuvsqM+sPvAXcDNxFBuzDk2zfR8mQfdiddG4RzAEq3H27u7cBC4C5IdckPXD3V4ADXWbPBZ5IvH+Cjn94aekE25cx3H23u69KvD8CvA2UkSH78CTbl9HSOQjKgKpO09Vk3g5z4Hdm9paZ3RN2MQEacewRpYnX4SHXE4T7zWxdousoLbtNujKzccBM4A0ycB922T7IwH14TDoHgXUzLz37uU7scnefBdwA3JfodpD08yNgAjAD2A18N9RqksDMSoBfAF9094aw60m2brYv4/ZhZ+kcBNXA6E7T5UBtSLUEwt1rE697gYV0dIdlorpE3+yxPtq9IdeTVO5e5+4xd48D/480349mlkfHQfIpd38uMTtj9mF325dp+7CrdA6CFcAkMxtvZvnAHcCikGtKGjMrTpyswsyKgeuADSf/VNpaBHwq8f5TwAsh1pJ0xw6QCfNI4/1oZgY8Drzt7g93WpQR+/BE25dJ+7A7aXvVEEDiEq7vAxFgvrt/M9yKksfMzqajFQCQCzydCdtnZv8BXEXHsL51wNeA54FngTHALuA2d0/LE64n2L6r6OhScGAn8BfH+tPTjZm9D/gjsB6IJ2Z/hY5+9LTfhyfZvjvJkH3YnbQOAhEROXPp3DUkIiJJoCAQEclyCgIRkSynIBARyXIKAhGRLJcbdgEi6erYYHLAAOAVd38x3IpETo+CQOQMuftDYdcgcibUNSRyCszs7xLPwHgRODcx7ydm9pHE+51m9o9mttzMVprZLDNbYmbbzOzeUIsXOQG1CER6ycwupGMok5l0/NtZRcd49V1VufulZvY94CfA5UA/YCPwaN9UK9J7CgKR3rsCWOjuzQBmdqKxrY7NXw+UJMa1P2JmLWY2yN0PBV+qSO+pa0jk1PRmTJbWxGu80/tj0/rPl6QcBYFI770CzDOzwsTIsB8KuyCRZND/TkR6KfEc22eANUAlHaNUiqQ9jT4qIpLl1DUkIpLlFAQiIllOQSAikuUUBCIiWU5BICKS5RQEIiJZTkEgIpLl/j/ZUCKzuyEzLQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FEATURES_CNT = 28\n",
    "df = pd.read_csv(\"MDS_Assignment1_furnace.csv\")\n",
    "pred = df.grade\n",
    "D = df[df.columns[:FEATURES_CNT]]\n",
    "X = sm.add_constant(D)\n",
    "est = sm.OLS(pred, X)\n",
    "result = est.fit()\n",
    "rank_list = [[f'f{i}', value] for i, value in enumerate(result.pvalues[1:])]\n",
    "rank_list = sorted(rank_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "dims = []\n",
    "adj_R2 = []\n",
    "for i in range(FEATURES_CNT):\n",
    "    features = [f[0] for f in rank_list[:i+1]]\n",
    "    X = sm.add_constant(df[features])\n",
    "    est = sm.OLS(pred, X)\n",
    "    result = est.fit()\n",
    "    dims.append(len(features))\n",
    "    adj_R2.append(result.rsquared_adj)\n",
    "\n",
    "plt.plot(dims, adj_R2)\n",
    "plt.xlabel(\"dim\")\n",
    "plt.ylabel(\"adj-R2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從圖中我們可發現，當維度增加，也就是不斷增加所選特徵時，adj_R2的數值不斷增加，甚至在選到p-value倒數的最後幾個指標時，此現象更為劇烈。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 試找一個開放數據(e.g. Kaggle 開放數據)，您會用什麼方法來確認資料品質的好壞？試操作一次並說明其細節。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(樣本個數, 特徵個數): (2000, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsiangan/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>price_range</td>   <th>  R-squared:         </th> <td>   0.919</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1117.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 22 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:33:05</td>     <th>  Log-Likelihood:    </th> <td> -552.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2000</td>      <th>  AIC:               </th> <td>   1147.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1979</td>      <th>  BIC:               </th> <td>   1264.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>   -1.5750</td> <td>    0.062</td> <td>  -25.553</td> <td> 0.000</td> <td>   -1.696</td> <td>   -1.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>battery_power</th> <td>    0.0005</td> <td> 1.64e-05</td> <td>   31.071</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blue</th>          <td>   -0.0020</td> <td>    0.014</td> <td>   -0.141</td> <td> 0.888</td> <td>   -0.030</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clock_speed</th>   <td>   -0.0121</td> <td>    0.009</td> <td>   -1.368</td> <td> 0.171</td> <td>   -0.029</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dual_sim</th>      <td>   -0.0237</td> <td>    0.014</td> <td>   -1.644</td> <td> 0.100</td> <td>   -0.052</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fc</th>            <td>    0.0009</td> <td>    0.002</td> <td>    0.432</td> <td> 0.666</td> <td>   -0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>four_g</th>        <td>   -0.0015</td> <td>    0.018</td> <td>   -0.083</td> <td> 0.934</td> <td>   -0.036</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>int_memory</th>    <td>    0.0009</td> <td>    0.000</td> <td>    2.178</td> <td> 0.030</td> <td> 8.61e-05</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_dep</th>         <td>   -0.0100</td> <td>    0.025</td> <td>   -0.399</td> <td> 0.690</td> <td>   -0.059</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mobile_wt</th>     <td>   -0.0009</td> <td>    0.000</td> <td>   -4.335</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_cores</th>       <td>    0.0018</td> <td>    0.003</td> <td>    0.579</td> <td> 0.563</td> <td>   -0.004</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc</th>            <td>    0.0001</td> <td>    0.002</td> <td>    0.083</td> <td> 0.934</td> <td>   -0.003</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>px_height</th>     <td>    0.0003</td> <td> 1.89e-05</td> <td>   14.626</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>px_width</th>      <td>    0.0003</td> <td> 1.94e-05</td> <td>   14.437</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ram</th>           <td>    0.0009</td> <td> 6.64e-06</td> <td>  142.688</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc_h</th>          <td>    0.0011</td> <td>    0.002</td> <td>    0.575</td> <td> 0.565</td> <td>   -0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc_w</th>          <td>   -0.0003</td> <td>    0.002</td> <td>   -0.171</td> <td> 0.864</td> <td>   -0.004</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talk_time</th>     <td>    0.0004</td> <td>    0.001</td> <td>    0.276</td> <td> 0.783</td> <td>   -0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>three_g</th>       <td>    0.0270</td> <td>    0.021</td> <td>    1.301</td> <td> 0.193</td> <td>   -0.014</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>touch_screen</th>  <td>   -0.0057</td> <td>    0.014</td> <td>   -0.397</td> <td> 0.691</td> <td>   -0.034</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wifi</th>          <td>   -0.0214</td> <td>    0.014</td> <td>   -1.489</td> <td> 0.137</td> <td>   -0.050</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>114.748</td> <th>  Durbin-Watson:     </th> <td>   1.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  43.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.038</td>  <th>  Prob(JB):          </th> <td>3.10e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.279</td>  <th>  Cond. No.          </th> <td>2.58e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.58e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            price_range   R-squared:                       0.919\n",
       "Model:                            OLS   Adj. R-squared:                  0.918\n",
       "Method:                 Least Squares   F-statistic:                     1117.\n",
       "Date:                Sat, 22 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        19:33:05   Log-Likelihood:                -552.26\n",
       "No. Observations:                2000   AIC:                             1147.\n",
       "Df Residuals:                    1979   BIC:                             1264.\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const            -1.5750      0.062    -25.553      0.000      -1.696      -1.454\n",
       "battery_power     0.0005   1.64e-05     31.071      0.000       0.000       0.001\n",
       "blue             -0.0020      0.014     -0.141      0.888      -0.030       0.026\n",
       "clock_speed      -0.0121      0.009     -1.368      0.171      -0.029       0.005\n",
       "dual_sim         -0.0237      0.014     -1.644      0.100      -0.052       0.005\n",
       "fc                0.0009      0.002      0.432      0.666      -0.003       0.005\n",
       "four_g           -0.0015      0.018     -0.083      0.934      -0.036       0.033\n",
       "int_memory        0.0009      0.000      2.178      0.030    8.61e-05       0.002\n",
       "m_dep            -0.0100      0.025     -0.399      0.690      -0.059       0.039\n",
       "mobile_wt        -0.0009      0.000     -4.335      0.000      -0.001      -0.000\n",
       "n_cores           0.0018      0.003      0.579      0.563      -0.004       0.008\n",
       "pc                0.0001      0.002      0.083      0.934      -0.003       0.003\n",
       "px_height         0.0003   1.89e-05     14.626      0.000       0.000       0.000\n",
       "px_width          0.0003   1.94e-05     14.437      0.000       0.000       0.000\n",
       "ram               0.0009   6.64e-06    142.688      0.000       0.001       0.001\n",
       "sc_h              0.0011      0.002      0.575      0.565      -0.003       0.005\n",
       "sc_w             -0.0003      0.002     -0.171      0.864      -0.004       0.003\n",
       "talk_time         0.0004      0.001      0.276      0.783      -0.002       0.003\n",
       "three_g           0.0270      0.021      1.301      0.193      -0.014       0.068\n",
       "touch_screen     -0.0057      0.014     -0.397      0.691      -0.034       0.022\n",
       "wifi             -0.0214      0.014     -1.489      0.137      -0.050       0.007\n",
       "==============================================================================\n",
       "Omnibus:                      114.748   Durbin-Watson:                   1.976\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.786\n",
       "Skew:                           0.038   Prob(JB):                     3.10e-10\n",
       "Kurtosis:                       2.279   Cond. No.                     2.58e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.58e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Mobile_Price_Classification.csv')\n",
    "\n",
    "n,m = df.shape\n",
    "\n",
    "# step 1: 取得樣本個數和特徵個數\n",
    "print(f\"(樣本個數, 特徵個數): ({n}, {m-1})\")\n",
    "\n",
    "# step 2: 用 OLS 係數檢測數值之間的合理性\n",
    "pred = df.price_range\n",
    "D = df[df.columns[:m-1]]\n",
    "X = sm.add_constant(D)\n",
    "est = sm.OLS(pred, X)\n",
    "result = est.fit()\n",
    "\n",
    "summary = est.fit().summary()\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 觀察每個特徵對應的相關係數，推論是否符合常理。例如，手機重量與價格成負相關、手機的 ram 數、核心數、鏡頭畫素成正比屬於合理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) 公司或您是否有現存方法來進行資料品質的確認？如果有(或沒有)，試依您的角度說明(或建議)確認資料品質的標準作業流程(i.e. SOP)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 我認為簡易的資料品質確認方法SOP：\n",
    "> - 視覺化資料的分佈情況\n",
    "> - 找出各指標基本的統計數值，如平均數、中位數、標準差、信賴區間等。\n",
    "> - 透過上述指標，可以找出資料分布是否有不平衡的狀況，若有，視情況補上或刪除資料以達成平衡。\n",
    "> - 用線性回歸的方法大致看看指標之間的關係是否符合常理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) 試建議三個可能衡量數據品質的量化指標(i.e. KPIs)。\n",
    "> - 數據分佈情況(distribution)以及平均值、變異數等統計指標\n",
    "> - 信度與效度\n",
    "> - 透過線性回歸的參數檢測數據之間的合理性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 在數據科學分析架構中的決策支援階段：什麼是模型的適應性與擴充性？\n",
    "> 模型的適應性指的是一個特定模型能夠良好的運作在何種背景、領域、資料分佈情況、時間限制內等指標(zero to many)。  \n",
    "> 模型的擴衝性是指模型在被建構出來後是否可以適用於訓練資料外的外來數據(one to many)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) 在 AI 專案中(可根據第一題的開放數據與模型)，就您所使用的數據與建構的預測模型是否具備適用性與擴充性？為什麼？又該如何調整與改善呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 我認為紅酒數據集不具有擴充性，很大的原因是他的特徵都已經被去資訊化了，也就是僅根據該 .csv 檔無從得知裡面的f1, f2到底是對應到什麼指標。對於新的資料集根本無法使用在這個模型。所以最簡單的調整法就是把特徵真實的定義加上，才能讓模型對於新資料有掌握的能力。(除非是f1, f2在紅酒的領域中擁有特定的意義，如此一來這些特徵才能被辨別)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 遺漏值填補的方法包括了統計量填補、預測式填補與生成式填補，試說明這些方法分別適用於什麼樣情形?\n",
    "> + 做統計量填補時，透過其他特徵找關係，有益於我們選擇想要的資訊。這樣的填補法適合有意控制資訊量的情況。例如在最大值、最小值或者中位數之間做缺漏值填補的選擇，反映了我們對於數據的期望以及信心。\n",
    "> + 預測式填補法適用於任務不需要太多超參數做調整且沒有太充份的時間可以做機器學習的情況。若已知資料屬於非線性關係，也適合用預測式填補來處理。\n",
    "> + 生成式填補需要用到機器學習甚至是深度學習的框架，適合用於任務本身十分複雜，擁有許多超參數需要調整的情況。若追求更高的準確度且時間充足，會是使用生成式填補的良好時機。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) 為什麼某特徵存在大量遺漏值不宜直接刪除？\n",
    "> 對於該特徵有值的少量數據可能存在特定的數據分佈或特徵，若直接刪除此項特徵可能間接導致無法觀察到這樣的現象，失去一個有效的衡量指標。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "在 UCI Machine Learning Repository 開放數據中包含了一個鋼板缺陷數據(steel plates faults dataset，https://archive.ics.uci.edu/ml/datasets/steel+plates+faults)，一共包含了1,941 個觀測值，而每個觀測值具有 27 個特徵以及作為目標值的 7 種缺陷。試挑選出凹凸不平(Bumps)以及刮痕(K_Scratch)兩種缺陷進行分析。試著參考網路資源學習並撰寫程式，使用此數據回答下列問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 試將羅吉斯迴歸分析的結果呈現如下表，並試著解釋任一特徵與目標值之間的關係。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.027633\n",
      "         Iterations: 35\n",
      "                       estimate  std.error  t-value  p-value\n",
      "            intercept   -74.898        NaN      NaN      NaN\n",
      "            X_Minimum    -0.432      0.452   -0.956    0.339\n",
      "            X_Maximum     0.433      0.451    0.959    0.338\n",
      "            Y_Minimum    -0.033      0.223   -0.147    0.883\n",
      "            Y_Maximum     0.033      0.223    0.147    0.883\n",
      "         Pixels_Areas    -0.033      0.014   -2.395    0.017\n",
      "          X_Perimeter    -0.140      0.080   -1.758    0.079\n",
      "          Y_Perimeter     0.168      0.123    1.365    0.172\n",
      "    Sum_of_Luminosity     0.000      0.000    2.134    0.033\n",
      "Minimum_of_Luminosity     0.301      0.113    2.660    0.008\n",
      "Maximum_of_Luminosity     0.494      0.233    2.120    0.034\n",
      "   Length_of_Conveyer    -0.008      0.012   -0.635    0.525\n",
      "     TypeOfSteel_A300   -36.599        NaN      NaN      NaN\n",
      "     TypeOfSteel_A400   -38.295        NaN      NaN      NaN\n",
      "Steel_Plate_Thickness     0.201      0.105    1.913    0.056\n",
      "          Edges_Index    11.970      4.034    2.968    0.003\n",
      "          Empty_Index    63.999     37.065    1.727    0.084\n",
      "         Square_Index    -0.590      3.752   -0.157    0.875\n",
      "      Outside_X_Index  -326.923    533.816   -0.612    0.540\n",
      "        Edges_X_Index   -24.280      8.730   -2.781    0.005\n",
      "        Edges_Y_Index    20.829      8.584    2.426    0.015\n",
      " Outside_Global_Index    -5.028      3.289   -1.529    0.126\n",
      "           LogOfAreas    77.577     47.537    1.632    0.103\n",
      "          Log_X_Index   -43.546     52.002   -0.837    0.402\n",
      "          Log_Y_Index  -111.125     55.934   -1.987    0.047\n",
      "    Orientation_Index    21.338     14.855    1.436    0.151\n",
      "     Luminosity_Index  -120.050     45.640   -2.630    0.009\n",
      "       SigmoidOfAreas    -5.979      6.415   -0.932    0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsiangan/opt/anaconda3/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py:1810: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/Users/hsiangan/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "# Load data from xlsx file\n",
    "excel_file = pd.ExcelFile('MDS_Assignment2_Steelplates.xlsx')\n",
    "vars = [var[0] for var in pd.read_excel(excel_file, 'Var_Name',header=None).values.tolist()]\n",
    "faults = vars[-7:]\n",
    "df = pd.read_excel(excel_file, 'Faults', names=vars)\n",
    "\n",
    "# pick out row includes data of both Bumps and K_Scratch to do analysis\n",
    "rows = df.loc[(df['Bumps'] == 1) | (df['K_Scatch'] == 1)]\n",
    "\n",
    "# get features-only data and error_type\n",
    "features = rows.drop(faults,axis=1).to_numpy()\n",
    "error_type = rows['Bumps'].values\n",
    "\n",
    "model = sm.Logit(error_type, sm.tools.add_constant(features)).fit()\n",
    "\n",
    "idx = ['intercept'] + vars[:-7]\n",
    "\n",
    "results = {\"\": idx, \"estimate\":model.params, \"std.error\":model.bse, \"t-value\":model.tvalues, \"p-value\":model.pvalues}\n",
    "\n",
    "table = pd.DataFrame(results)\n",
    "print(table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Luminosity_Index 和 bumps 之間的相關性為 -120.050，呈高度負相關性。代表當亮度越高，越有可能是凹凸不平的現象，非常符合人類的預期。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) 基於上述(a)的結果，將上述特徵以 t value 進行排序後，哪些特徵的迴歸係數在統計\n",
    "上是顯著的呢(p-value<0.01)？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           estimate  std.error  t-value  p-value\n",
      "19          Edges_X_Index   -24.280      8.730   -2.781    0.005\n",
      "26       Luminosity_Index  -120.050     45.640   -2.630    0.009\n",
      "9   Minimum_of_Luminosity     0.301      0.113    2.660    0.008\n",
      "15            Edges_Index    11.970      4.034    2.968    0.003\n"
     ]
    }
   ],
   "source": [
    "vars = table.sort_values(by=['t-value'])\n",
    "sig_vars = vars[vars['p-value'] < 0.01]\n",
    "print(sig_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Edges_X_Index, Luminosity_Index, Minimum_of_Luminosity, Edges_Index 為四個符合顯著定義的特徵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 試問配適一個羅吉斯迴歸模型是否合適？試若配適不佳，試說明其可能的原因為何?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 以下將試著用 train test split, 並以 mAE, P/R/F1 和 auc 作為 evalation 的參考指標。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Percision/Recall/F1Score': (array([0.95 , 0.975]),\n",
      "                              array([0.97435897, 0.95121951]),\n",
      "                              array([0.96202532, 0.96296296]),\n",
      "                              array([39, 41])),\n",
      " 'auc': 0.9924953095684803,\n",
      " 'mAE': 0.0375}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, precision_recall_fscore_support, roc_auc_score\n",
    "import pprint\n",
    "# data splitting\n",
    "# train: test = 9: 1\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, error_type,train_size=0.9)\n",
    "\n",
    "# create model and feed data\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "# train model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "eval_table = {\n",
    "    \"mAE\" : mean_absolute_error(y_test, pred),\n",
    "    \"Percision/Recall/F1Score\" : precision_recall_fscore_support(y_test, pred),\n",
    "    \"auc\" : roc_auc_score(y_test, model.predict_proba(x_test)[:,1])\n",
    "}\n",
    "\n",
    "pprint.pprint(eval_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 從P/R和 F1 score 能輕易看出模型的準確度是足夠好的。另外AUC為0.994，十分接近1，也是個非常好的表現數據。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) 試問配適一個線性判別分析模型是否合適？若配適不佳，試說明其可能的原因為何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Percision/Recall/F1Score': (array([1.        , 0.95454545]),\n",
      "                              array([0.94736842, 1.        ]),\n",
      "                              array([0.97297297, 0.97674419]),\n",
      "                              array([38, 42])),\n",
      " 'auc': 0.9981203007518797,\n",
      " 'mAE': 0.025}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# create model and feed data\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# train model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "eval_table = {\n",
    "    \"mAE\" : mean_absolute_error(y_test, pred),\n",
    "    \"Percision/Recall/F1Score\" : precision_recall_fscore_support(y_test, pred),\n",
    "    \"auc\" : roc_auc_score(y_test, model.predict_proba(x_test)[:,1])\n",
    "}\n",
    "\n",
    "pprint.pprint(eval_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 從 P/R F1 score 來看，線性判別分析模型和羅吉斯模型的表現十分相近，線性判別分析模型的 auc 更提高了一些，mAE 也下降到 0.025。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) 試問配適一個二次判別分析模型是否合適？若配適不佳，試說明其可能的原因為\n",
    "何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Percision/Recall/F1Score': (array([1.        , 0.91304348]),\n",
      "                              array([0.89473684, 1.        ]),\n",
      "                              array([0.94444444, 0.95454545]),\n",
      "                              array([38, 42])),\n",
      " 'auc': 0.9993734335839599,\n",
      " 'mAE': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsiangan/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# create model and feed data\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "# train model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "eval_table = {\n",
    "    \"mAE\" : mean_absolute_error(y_test, pred),\n",
    "    \"Percision/Recall/F1Score\" : precision_recall_fscore_support(y_test, pred),\n",
    "    \"auc\" : roc_auc_score(y_test, model.predict_proba(x_test)[:,1])\n",
    "}\n",
    "\n",
    "pprint.pprint(eval_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">同樣從 P/R 和 F1 score ，以及 auc 的數據表現來看，二次判別分析的準確度都還不錯，但相比羅吉斯與線性判別模型各指標標都差了一些，尤其是mAE，來到0.5。不過對於這個任務，二次判別模型依舊是適和的選擇。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11771b763e3100d5b4cc94c3c504f3fcaa1606af72b03a39a85461e19ccfaadf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
